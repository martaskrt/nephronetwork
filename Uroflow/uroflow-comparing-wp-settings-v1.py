# -*- coding: utf-8 -*-
"""cleaning_uroflow_files_v2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zzcSwQ108S1UzT1nXwQT3zYhjGLGY7WT
"""

# !pip install pydub
# !pip install ffmpeg
# !pip install scikit-sound
# !pip install pygame
# !pip install audiosegment

# from pydub import AudioSegment
import os
# import ffmpeg
# from sksound.sounds import Sound
import audiosegment ## install
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import string
from scipy.interpolate import interp1d
# from google.colab import drive
import random
# drive.mount('/content/drive/',force_remount=True)

"""###Reading in audio files"""

audio_list = []
set_name = []
audio_file_names = []
full_audio_list = []
freqs_list = []
times_list = []
amplitudes_list = []

sets_to_preprocess = ['Water','Hwater','Human','Bgnwater','Bgpcwater']

# audio_folder = '/content/drive/My Drive/Uroflow analysis/Audio/HumanAndWater/'

for my_set in sets_to_preprocess:
  audio_folder = '/content/drive/My Drive/Uroflow analysis/Audio/' + my_set + '/'

  for file in os.listdir(audio_folder):
      set_name.append(my_set)
  #   if file[0:3] == "fem":
      print(file)   
      print(my_set)
      in_seg = audiosegment.from_file(audio_folder + file)
      freqs, times, amplitudes = in_seg.spectrogram(window_length_s=0.06, overlap=0.5)
      amplitudes = 10 * np.log10(amplitudes + 1e-9)
      seg_array = np.array(in_seg.get_array_of_samples())

      freqs_list.append(freqs)
      times_list.append(times)
      amplitudes_list.append(amplitudes)

      full_audio_list.append(in_seg)
      audio_list.append(seg_array)
      audio_file_names.append(file)

# from: https://www.geeksforgeeks.org/python-intersection-two-lists/
def intersection(lst1, lst2): 
    lst3 = [value for value in lst1 if value in lst2] 
    return lst3


# plt.plot(freqs_list[0])

"""###Reading in uroflow curve data"""

curves = []
curves_sub = []
curve_file_names = []
time_axis_list = []
audio_list_sub = []
full_audio_list_sub = []
freqs_list_sub = []
times_list_sub = []
amplitudes_list_sub = []

# curve_folder = '/content/drive/My Drive/Uroflow analysis/Curves/HumanAndWater/'

i = 0
for j in range(len(audio_file_names)):
# for file in audio_file_names:
  file = audio_file_names[j]
  print(file)
#for file in os.listdir('/content/drive/My Drive/Uroflow analysis/Curves/'):
  curve_folder = '/content/drive/My Drive/Uroflow analysis/Curves/' + set_name[j] + '/'
  print(curve_folder)
  curve_file_name = file.split(".")[0] + ".csv"  
  j = j + 1
  if curve_file_name in os.listdir(curve_folder):
      print(curve_file_name)
#     if curve_file_name[0:3] == "Fem":
      in_file = pd.read_csv(curve_folder + curve_file_name, header=None)
      in_file.columns = ['x','y']
      # print(in_file.head)
      curves.append(in_file)
      audio_list_sub.append(audio_list[i])
      full_audio_list_sub.append(full_audio_list[i])
      curves[i]['new_x'] = curves[i].x - min(curves[i].x)

      new_times = [x for x in times_list[i] if x < max(curves[i]['new_x'])]
      
      print(len(new_times))
      
      times_list_sub.append(np.array(new_times))
      
      freqs_list_sub.append(freqs_list[i])
      
      amplitudes_list_sub.append(amplitudes_list[i][:,0:len(new_times)])
#       print(amplitudes_list_sub[i][:,0:len(new_times)].shape)
      
            
#       curves_sub.append(in_file.loc[in_file['new_x'] < max(times_list_sub[i])])
      curves_sub.append(in_file)
      curve_file_names.append(file)
      i = i+1

"""###Interpolating curves to match audio file"""

resampled_curves = []

for sample in range(len(audio_list_sub)):
  #print(sample)
  int_curve = interp1d(x = curves[sample].new_x, y = curves[sample].y)
  resampled_curves.append(int_curve(times_list_sub[sample]))

"""###Adding time to amplitude data"""

freq_lens = []

for my_freq in freqs_list:
  freq_lens.append(len(my_freq))

cat_amplitudes_list_sub = []

for sample in range(len(amplitudes_list_sub)):
  # print(sample)
  cat_amplitudes_list_sub.append(np.concatenate((amplitudes_list_sub[sample][0:min(freq_lens)],times_list_sub[sample].reshape(1,-1)),axis=0))

"""###Combining data into singe file"""

out_list = [curve_file_names,times_list_sub,cat_amplitudes_list_sub,resampled_curves,set_name]

# for sample in range(len(resampled_curves)):
  # print(resampled_curves[sample].shape)
  # print(times_list_sub[sample].shape)
  # print(cat_amplitudes_list_sub[sample].shape)
  # print(curve_file_names[sample])

"""###Create subsampled data"""

def make_subsamples(sample_len = 300,in_list = out_list,n_samples = 50, seed_val = 1324,
                    sample_files = ['Water1.m4a','Bgnwater2.m4a','Bgpcwater2.m4a','Hwater2.m4a','Male1.m4a','Male2.m4a','Male6.m4a','Female2.m4a','Female3.m4a','Female4.m4a']):
  random.seed(seed_val)

  file_name = in_list[0]
  time_axis = in_list[1]
  audio_list = in_list[2]
  curve_list = in_list[3]
  my_set_name = in_list[4]
  
  ft_samp_name = []
  ft_samp_time_axis = []
  ft_samp_audio_list = []
  ft_samp_curve_list = []
  ft_samp_set_name = []

  samp_name = []
  samp_time_axis = []
  samp_audio_list = []
  samp_curve_list = []
  samp_set_name = []

  val_samp_name = []
  val_samp_time_axis = []
  val_samp_audio_list = []
  val_samp_curve_list = []
  val_samp_set_name = []

  ## same test data across all experiments
  test_samp_name = []
  test_samp_time_axis = []
  test_samp_audio_list = []
  test_samp_curve_list = []
  test_samp_set_name = []

  ## subsampled test set for graphing
  sub_test_samp_name = []
  sub_test_samp_time_axis = []
  sub_test_samp_audio_list = []
  sub_test_samp_curve_list = []
  sub_test_samp_set_name = []

  for i in range(len(file_name)):
    print(file_name[i])
    # print("iteration"+str(i))
    min_curve_len = min(time_axis[i].size,audio_list[i].size,curve_list[i].size)
    # print(min_curve_len)
    
    new_time_axis = time_axis[i][0:min_curve_len]
    new_audio_list = audio_list[i][:,0:min_curve_len]
    new_curve_list = curve_list[i][0:min_curve_len]

    if file_name[i] in sample_files:
      test_samp_name.append(file_name[i].split(".")[0])
      test_samp_time_axis.append(new_time_axis)
      test_samp_audio_list.append(new_audio_list)
      test_samp_curve_list.append(new_curve_list)
      test_samp_set_name.append(my_set_name[i])

      for samp_i in range(n_samples):
        #print("stop range" + str((min_curve_len - (sample_len+1))))
        time_start = random.randrange(start = 0, stop = (min_curve_len - (sample_len+1)))
        time_stop = time_start + sample_len

        sub_test_samp_name.append(file_name[i].split(".")[0] + "_" + str(samp_i))
        sub_test_samp_time_axis.append(new_time_axis[time_start:time_stop])
        sub_test_samp_audio_list.append(new_audio_list[:,time_start:time_stop])
        sub_test_samp_curve_list.append(new_curve_list[time_start:time_stop])
        sub_test_samp_set_name.append(my_set_name[i])

        if samp_i < 1:
          samp_name.append(file_name[i].split(".")[0] + "_" + str(samp_i))
          samp_time_axis.append(new_time_axis[time_start:time_stop])
          samp_audio_list.append(new_audio_list[:,time_start:time_stop])
          samp_curve_list.append(new_curve_list[time_start:time_stop])
          samp_set_name.append(my_set_name[i])


    elif file_name[i].split(".")[0][-2:] in ["11","12"]:
      print("Validation sample: " + file_name[i])
      for samp_i in range(n_samples):
        #print("stop range" + str((min_curve_len - (sample_len+1))))
        time_start = random.randrange(start = 0, stop = (min_curve_len - (sample_len+1)))
        time_stop = time_start + sample_len
    
        val_samp_name.append(file_name[i].split(".")[0] + "_" + str(samp_i))
        val_samp_time_axis.append(new_time_axis[time_start:time_stop])
        val_samp_audio_list.append(new_audio_list[:,time_start:time_stop])
        val_samp_curve_list.append(new_curve_list[time_start:time_stop])
        val_samp_set_name.append(my_set_name[i])

        ft_samp_name.append(file_name[i].split(".")[0] + "_" + str(samp_i))
        ft_samp_time_axis.append(new_time_axis[time_start:time_stop])
        ft_samp_audio_list.append(new_audio_list[:,time_start:time_stop])
        ft_samp_curve_list.append(new_curve_list[time_start:time_stop])
        ft_samp_set_name.append(my_set_name[i])

        if samp_i < 1:
          samp_name.append(file_name[i].split(".")[0] + "_" + str(samp_i))
          samp_time_axis.append(new_time_axis[time_start:time_stop])
          samp_audio_list.append(new_audio_list[:,time_start:time_stop])
          samp_curve_list.append(new_curve_list[time_start:time_stop])
          samp_set_name.append(my_set_name[i])


    else:
      for samp_i in range(n_samples):
        #print("stop range" + str((min_curve_len - (sample_len+1))))
        time_start = random.randrange(start = 0, stop = (min_curve_len - (sample_len+1)))
        time_stop = time_start + sample_len

        samp_name.append(file_name[i].split(".")[0] + "_" + str(samp_i))
        samp_time_axis.append(new_time_axis[time_start:time_stop])
        samp_audio_list.append(new_audio_list[:,time_start:time_stop])
        samp_curve_list.append(new_curve_list[time_start:time_stop])
        samp_set_name.append(my_set_name[i])

        ft_samp_name.append(file_name[i].split(".")[0] + "_" + str(samp_i))
        ft_samp_time_axis.append(new_time_axis[time_start:time_stop])
        ft_samp_audio_list.append(new_audio_list[:,time_start:time_stop])
        ft_samp_curve_list.append(new_curve_list[time_start:time_stop])
        ft_samp_set_name.append(my_set_name[i])

    ft_training_list = [ft_samp_name,ft_samp_time_axis,ft_samp_audio_list,ft_samp_curve_list,ft_samp_set_name]
    training_list = [samp_name,samp_time_axis,samp_audio_list,samp_curve_list,samp_set_name]
    val_list = [val_samp_name,val_samp_time_axis,val_samp_audio_list,val_samp_curve_list,val_samp_set_name]
    
    test_list = [test_samp_name,test_samp_time_axis,test_samp_audio_list,test_samp_curve_list,test_samp_set_name]
    sub_test_list = [sub_test_samp_name,sub_test_samp_time_axis,sub_test_samp_audio_list,sub_test_samp_curve_list,sub_test_samp_set_name]

  return ft_training_list,training_list,val_list,test_list,sub_test_list

ft_training,training,val,test,sub_test = make_subsamples()

# training[0]

# val[0]

# test[0]

# ft_training,training,val,test,sub_test
# np.save('/content/drive/My Drive/Uroflow analysis/multisetting_v1_ft',ft_training)
# np.save('/content/drive/My Drive/Uroflow analysis/multisetting_v1_train',training)
# np.save('/content/drive/My Drive/Uroflow analysis/multisetting_v1_val',val)
# np.save('/content/drive/My Drive/Uroflow analysis/multisetting_v1_test',test)
# np.save('/content/drive/My Drive/Uroflow analysis/multisetting_v1_sub_test',sub_test)

"""###UMAP"""

!pip install umap-learn

import numpy as np
from sklearn.datasets import load_iris, load_digits
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import seaborn as sns
import pandas as pd
import umap

ft_audio_flat = np.array(ft_training[2]).reshape(len(ft_training[2]),-1)

training_audio_df = pd.DataFrame(ft_audio_flat)
training_curve_df = pd.DataFrame(ft_training[3])

training_audio_df.head

reducer = umap.UMAP()
embedding_curve = reducer.fit_transform(training_curve_df)
embedding_audio = reducer.fit_transform(training_audio_df)

def setting_to_num(setting_list):
    set_dict = {'Human' : 1,
                'Water' : 2,
                'Hwater' : 3,
                'Bgnwater' : 4,
                'Bgpcwater' : 5
    }
    num_list = [set_dict[item] for item in setting_list]
    return num_list


# setting_to_num(ft_training[4])

fig, ax = plt.subplots()
scatter = ax.scatter(embedding_curve[:, 0], embedding_curve[:, 1],
                     s=4,
                     cmap=ListedColormap(['b','g','r','c','m']),c = setting_to_num(ft_training[4]))
legend_curve = ax.legend(handles=scatter.legend_elements()[0],labels = ['Human','Water','Human-like water','Background Music','Background Podcast'],
                         loc="upper center",title="Setting",
                         bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)
# ax.add_artist(legend_audio)
plt.savefig('curve-umap.png')
plt.show()

fig, ax = plt.subplots()
scatter = ax.scatter(embedding_audio[:, 0], embedding_audio[:, 1],
                     s=4,
                     cmap=ListedColormap(['b','g','r','c','m']),c = setting_to_num(ft_training[4]))
legend_audio = ax.legend(handles=scatter.legend_elements()[0],labels = ['Human','Water','Human-like water','Background Music','Background Podcast'],
                         loc="upper center",title="Setting",
                         bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)
# ax.add_artist(legend_audio)
plt.savefig('audio-umap.png')
plt.show()

"""### NN prep and training"""

! pip3 uninstall --yes tb-nightly tensorboard tensorflow-estimator tensorflow-gpu tf-estimator-nightly
! pip3 install tf-nightly
! pip3 install --upgrade grpcio

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import os
import torch
from torch import nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import transforms
import importlib.machinery
from torch.utils.data import Dataset, DataLoader
import argparse
from torch.autograd import Variable
from sklearn.utils import class_weight
import sys
import matplotlib.pyplot as plt
import datetime
from torch.utils.tensorboard import SummaryWriter
import tensorflow.compat.v2 as tf 
from tensorflow.compat.v2 import summary
# %load_ext tensorboard

"""###Data Loader"""

class UroflowDataset(Dataset):
  """Data loader for Uroflow sound and curve"""
  
  def __init__(self,ids,x,y): ## urodat[0], urodat[2], urodat[3]
    self.list_IDs = ids
    self.y = y
    self.x = x
  
  def __len__(self):
    return len(self.list_IDs)
  
  def __getitem__(self,index):
    y = torch.tensor(self.y[index]).float().unsqueeze(0)
    x = torch.tensor(self.x[index]).float().unsqueeze(0)
    
    return x,y
  
class UroflowDataset_withTime(Dataset):
  """Data loader for Uroflow sound and curve"""
  
#   def __init__(self,ids,x,y,time): ## urodat[0], urodat[2], urodat[3], urodat[1]
  def __init__(self,ids,x,y,channels,set_names=None,set_ids = ['Water','Human','Hwater','Bgnwater','Bgpcwater'],is_test = False): ## urodat[0], urodat[2], urodat[3]
    #new_times = [x for x in times_list[i] if x < max(curves[i]['new_x'])]

    if is_test: 
      x_sub = x
      y_sub = y
      id_sub = ids 

      self.list_IDs = id_sub
      self.y = y_sub
      self.x = x_sub
      self.channels = channels

    else: 
      x_sub = []
      y_sub = []
      id_sub = [] 

      for i in range(len(x)):     
        if set_names[i] in set_ids:   
          x_sub.append(x[i])
          y_sub.append(y[i])
          id_sub.append(ids[i])

      self.list_IDs = id_sub
      self.y = y_sub
      self.x = x_sub
      self.channels = channels
  #     self.time = time
  
  def __len__(self):
    return len(self.list_IDs)
  
  def __getitem__(self,index):
    
#     min_len = np.min([len(self.y[index]),len(self.x[index]),len(self.time[index])])
    
    y = torch.tensor(self.y[index]).float()#[0:min_len].unsqueeze(0)
    x = torch.tensor(self.x[index]).float().unsqueeze(0)#.view(1,self.channels,-1)#[0:min_len].view(1,1,-1)
    # x = torch.tensor(self.x[index]).float()#.view(1,self.channels,-1)#[0:min_len].view(1,1,-1)
#     time = torch.tensor(self.time[index]).float()[0:min_len].view(1,1,-1)

#     cat_out = torch.cat((x,time),1)
    
    return x,y

"""###Simple Feed-Forward Dilated CNN + LSTM"""

class MyLSTM(nn.Module):
  def __init__(self,in_channels, num_conv_filters=32, final_fc_layer = 32):
    super(MyLSTM,self).__init__()
    
    self.in_channels = in_channels
    
    self.conv0 = nn.Conv1d(in_channels,num_conv_filters,5,padding=10,dilation = 5)
    self.conv = nn.Conv1d(num_conv_filters,num_conv_filters,5,padding=10,dilation = 5)
    
    self.bn = nn.BatchNorm1d(num_conv_filters)
    
    self.lstm = nn.LSTM(num_conv_filters,final_fc_layer,1,batch_first = True)
    
    self.fc2 = nn.Linear(final_fc_layer,1)
        
  def forward(self,x):
    
    x0 = F.relu(self.bn(self.conv0(x)))
    x1 = F.relu(self.bn(self.conv(x0)))
    x2 = F.relu(self.bn(self.conv(x1)))
    x3 = F.relu(self.bn(self.conv(x2)))
    x4 = F.relu(self.bn(self.conv(x3)))
    x5 = F.relu(self.bn(self.conv(x4)))
    x6 = F.relu(self.bn(self.conv(x5)))
    
#     x5,hiddens = self.lstm(x4.unsqueeze(0))
    x7,hiddens = self.lstm(torch.transpose(x6,1,2))
    
    out = self.fc2(x7)
        
    return out
#     return x4

"""###Feed-Forward Dilated CNN + FWD/BKWD LSTM"""

class MyLSTM_fwdbkwd(nn.Module):
  def __init__(self,in_channels, num_conv_filters=32, final_fc_layer = 32):
    super(MyLSTM_fwdbkwd,self).__init__()
    
    self.in_channels = in_channels
    
    self.conv0 = nn.Conv1d(in_channels,num_conv_filters,5,padding=10,dilation = 5)
    self.conv = nn.Conv1d(num_conv_filters,num_conv_filters,5,padding=10,dilation = 5)
    
    self.bn = nn.BatchNorm1d(num_conv_filters)
    
    self.lstm = nn.LSTM(num_conv_filters,final_fc_layer,1,batch_first = True)
    
    self.fc2 = nn.Linear(final_fc_layer*2,1)
        
  def forward(self,x):
    
    x0 = F.relu(self.bn(self.conv0(x)))
    x1 = F.relu(self.bn(self.conv(x0)))
    x2 = F.relu(self.bn(self.conv(x1)))
    x3 = F.relu(self.bn(self.conv(x2)))
    x4 = F.relu(self.bn(self.conv(x3)))
    x5 = F.relu(self.bn(self.conv(x4)))
    x6 = F.relu(self.bn(self.conv(x5)))
    
#     x5,hiddens = self.lstm(x4.unsqueeze(0))
    lstm_in1 = torch.transpose(x6,1,2)
    lstm_in2 = torch.flip(lstm_in1,[1])

    x7,hiddens = self.lstm(lstm_in1)

    x8,hiddens = self.lstm(lstm_in2)

    x8_rev = torch.flip(x8,[1])

    x9 = torch.cat((x7,x8),2)
    
    out = self.fc2(x9)
        
    return out
    # return x7,x8

"""###Initializing training function"""

### HYPER-PARAMETERS
my_learning_rate = 0.001
my_momentum=0.9
# num_channels = 722
seg_length = training[2][4].shape[1]
my_num_channels = test[2][0].shape[0]
batch_size = 1  
my_max_epochs = 400
my_num_conv_filt = 128
my_final_fc_size = 128
device='cuda'
my_nn = MyLSTM_fwdbkwd

train_data = training
val_data = val
ft_train_data = ft_training
# analysis_set = ['Water']
analysis_set = ['Human','Bgnwater','Bgpcwater','Water','Hwater']
# train_data = handw_train_urodat_sub
# val_data = handw_val_urodat_sub
# fulltrain_data = 

## Weight initialization code from: Joseph Konan's response on https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch
random.seed(1234)
def init_weights(m):
    if type(m) == nn.Linear:
      torch.nn.init.xavier_uniform_(m.weight)
      m.bias.data.fill_(0.01)
    if type(m) == nn.Conv1d:
      torch.nn.init.xavier_uniform_(m.weight)
      m.bias.data.fill_(0.01)

def initialize_training(training_list,data_set_class,network_class,
                        num_chan,num_conv_filt,final_fc_size,device,
                        val_list = None,is_training_run=True,
                        do_init_weights=True,my_set=analysis_set):
  
  net = network_class(in_channels=num_chan, num_conv_filters =num_conv_filt, final_fc_layer = final_fc_size).to(device)
  if do_init_weights:
    net.apply(init_weights)

  if is_training_run:
    training_set = data_set_class(training_list[0], training_list[2], training_list[3], num_chan, training_list[4], my_set)
    val_set = data_set_class(val_list[0], val_list[2], val_list[3], num_chan, val_list[4], my_set)

    train_loader = DataLoader(training_set,shuffle = True)
    val_loader = DataLoader(val_set,shuffle = False)

    return net,train_loader,val_loader 

  else:
    training_set = data_set_class(training_list[0], training_list[2], training_list[3], num_chan, training_list[4], my_set)
    train_loader = DataLoader(training_set,shuffle = True)

    return net, train_loader

"""###Full Training Loop -- full set, LSTM"""

def training_loop(max_epochs,network_mod, training_dloader, 
                  learning_rate,momentum,
                  val_dloader=None, return_net = False):

  ## Try faster learning rate for this one
  per_epoch_loss = []
  train_mean_loss = []
  val_mean_loss = []

  criterion = nn.MSELoss()
  optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)

  for epoch in range(max_epochs):
    train_epoch_loss = []
    val_epoch_loss = []

    for idx,(x,y) in enumerate(train_loader):
      # print(idx)
      
      # print("x shape:")
      # print(x.squeeze(0).shape)
      # print("x:")
      # print(x)

      out = net(x.squeeze(0).to(device))
      # out1,out2 = net(x.squeeze(0).to(device))

      # print("cnn output1:")
      # print(out1)
      # print("cnn shape:")
      # print(out1.shape)

      # print("cnn output2:")
      # print(out2)
      # print("cnn shape:")
      # print(out2.shape)

      # test_cat = torch.cat((out1,out2),2)    
      # print("test_cat shape:")
      # print(test_cat.shape)

      loss = criterion(out.squeeze(),y.to(device).squeeze())
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()    
      train_epoch_loss.append(loss.item())
    
    train_mean_loss.append(np.mean(np.array(train_epoch_loss)))

    if val_dloader != None:      
      for idx_val, (x_val,y_val) in enumerate(val_loader):
        # print("x_val shape:")
        # print(x_val.squeeze(0).shape)
        
        out_val = net(x_val.squeeze(0).to(device))
        loss_val = criterion(out_val.squeeze(),y_val.to(device).squeeze())
        val_epoch_loss.append(loss_val.item())
      
      val_mean_loss.append(np.mean(np.array(val_epoch_loss)))
      print('epoch: %d, train loss: %.3f' %
            (epoch + 1, train_mean_loss[epoch]))
      print('epoch: %d, val loss: %.3f' %
            (epoch + 1, val_mean_loss[epoch]))
      with train_summary_writer.as_default():
              tf.summary.scalar('train_loss', train_mean_loss[epoch], step=epoch)
      with train_summary_writer.as_default():
              tf.summary.scalar('val_loss', val_mean_loss[epoch],step=epoch)
    else:
       with train_summary_writer.as_default():
              tf.summary.scalar('full_train_loss', train_mean_loss[epoch], step=epoch)
       print('epoch: %d, train loss: %.3f' %
             (epoch + 1, train_mean_loss[epoch]))

  return train_mean_loss,val_mean_loss

  if return_net: 
    return net,train_mean_loss,val_mean_loss

"""### Launch tensorboard and run training loop"""

current_time = str(datetime.datetime.now().timestamp())
train_log_dir = '/content/drive/My Drive/logs/tensorboard/uroflow/cross_settings/' + '_'.join(analysis_set) + '/' + current_time
test_log_dir = '/content/drive/My Drive/logs/tensorboard/uroflow/cross_settings/' + '_'.join(analysis_set) + '/' + current_time
train_summary_writer = summary.create_file_writer(train_log_dir)
test_summary_writer = summary.create_file_writer(test_log_dir)

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir /content/drive/My\ Drive/logs/tensorboard/uroflow/

print('Training data: ' + '_'.join(analysis_set))

"""### Training with a validation set"""

net, train_loader, val_loader = initialize_training(training_list=train_data,
                                                    data_set_class = UroflowDataset_withTime,
                                                    network_class = my_nn,
                        num_chan=my_num_channels,num_conv_filt=my_num_conv_filt,
                        final_fc_size=my_final_fc_size,device='cuda',
                        val_list=val_data,
                        is_training_run=True)

train_mean_mse, val_mean_mse = training_loop(max_epochs=my_max_epochs,network_mod=net, training_dloader=train_loader, 
                  learning_rate=my_learning_rate,momentum=my_momentum, 
                  val_dloader=val_loader, return_net = False)

# torch.save(net, 'Training data: ' + '_'.join(analysis_set) + '.pt')
# net = torch.load('Training data: ' + '_'.join(analysis_set) + '.pt')

"""###Full training set"""

net, ft_train_loader = initialize_training(training_list=ft_train_data,
                                                    data_set_class = UroflowDataset_withTime,
                                                    network_class = my_nn,
                        num_chan=my_num_channels,num_conv_filt=my_num_conv_filt,
                        final_fc_size=my_final_fc_size,device='cuda',
                        is_training_run=False)

training_loop(max_epochs=200,network_mod=net, training_dloader=ft_train_loader, 
                  learning_rate=my_learning_rate,momentum=my_momentum, return_net = False)

"""###Predicted output"""

test_set = UroflowDataset_withTime(test[0], test[2], test[3], my_num_channels,is_test=True)
test_loader = DataLoader(test_set,shuffle = False)

test_loss = []

for idx_val,(x_val,y_val) in enumerate(test_loader):
    #print(x_val)
    #print(net(x_val.squeeze(0).to(device)))
    out_val = net(x_val.squeeze(0).to(device))
    criterion = nn.MSELoss()
    loss_val = criterion(out_val.squeeze(),y_val.to(device).squeeze())
    num_segs = np.divide(len(y_val[0]),seg_length)
    scaled_loss_val = np.divide(loss_val.item(),num_segs)
    # print(len(y_val[0]))
    print('Test sample: ' + str(test[0][idx_val]) + ',' + str(idx_val) + ', Total loss: ' + str(loss_val.item()) + ', Scaled loss: ' + str(scaled_loss_val))

    # val_epoch_loss.append(loss_val.item())

    # test_loss.append(np.mean(np.array(test_loss)))

    # print('sample: %s, train loss: %.3f' %
    #       (test_urodat_sub[0][idx_val], test_loss[idx_val]))

def graph_test_prediction(test_y,test_x,channels=my_num_channels):
    y = torch.tensor(test_y).float()#[0:min_len].unsqueeze(0)
    x = torch.tensor(test_x).float().view(1,channels,-1)#[0:min_len].view(1,1,-1)
    pred_curve = net(x.to(device))
    plt.plot(pred_curve.squeeze().to('cpu').detach().numpy())
    plt.plot(y.squeeze().detach().numpy())
    plt.show()

subject = 0
print(test[0][subject])
graph_test_prediction(test[3][subject],test[2][subject])

subject = 1
print(test[0][subject])
graph_test_prediction(test[3][subject],test[2][subject])

subject = 2
print(test[0][subject])
graph_test_prediction(test[3][subject],test[2][subject])

subject = 3
print(test[0][subject])
graph_test_prediction(test[3][subject],test[2][subject])

subject = 4
print(test[0][subject])
graph_test_prediction(test[3][subject],test[2][subject])

subject = 5
print(test[0][subject])
graph_test_prediction(test[3][subject],test[2][subject])

subject = 6
print(test[0][subject])
graph_test_prediction(test[3][subject],test[2][subject])

subject = 7
print(test[0][subject])
graph_test_prediction(test[3][subject],test[2][subject])

subject = 8
print(test[0][subject])
graph_test_prediction(test[3][subject],test[2][subject])

subject = 9
print(test[0][subject])
graph_test_prediction(test[3][subject],test[2][subject])